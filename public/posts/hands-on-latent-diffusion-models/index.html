<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=53753&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  
    <meta http-equiv="content-language" content="en">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color">

  
  
    <title>Hands on with Latent Diffusion Models &middot; Patrick Schnaß | AI Advisory</title>
    <meta name="title" content="Hands on with Latent Diffusion Models &middot; Patrick Schnaß | AI Advisory">
  

  
  
    <meta name="description" content="Learn how to use Latent Diffusion Models to generate images.">
  
  
    <meta name="keywords" content="DallE,stable-diffusion,latent-diffusion-models,NoCode,HuggingFace,HandsOn,">
  
  
  
  <link rel="canonical" href="http://localhost:53753/posts/hands-on-latent-diffusion-models/">
  

  
  
    <meta name="author" content="Patrick Schnaß">
  
  
    
      
        
          <link href="https://www.linkedin.com/in/patrickschnass/" rel="me">
        
      
    
      
        
          <link href="https://github.com/PatrickPT" rel="me">
        
      
    
  

  
  <meta property="og:url" content="http://localhost:53753/posts/hands-on-latent-diffusion-models/">
  <meta property="og:site_name" content="Patrick Schnaß | AI Advisory">
  <meta property="og:title" content="Hands on with Latent Diffusion Models">
  <meta property="og:description" content="Learn how to use Latent Diffusion Models to generate images.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-01-13T09:28:09+00:00">
    <meta property="article:modified_time" content="2023-01-13T09:28:09+00:00">
    <meta property="article:tag" content="DallE">
    <meta property="article:tag" content="Stable-Diffusion">
    <meta property="article:tag" content="Latent-Diffusion-Models">
    <meta property="article:tag" content="NoCode">
    <meta property="article:tag" content="HuggingFace">
    <meta property="article:tag" content="HandsOn">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Hands on with Latent Diffusion Models">
  <meta name="twitter:description" content="Learn how to use Latent Diffusion Models to generate images.">

  
  
  
  
    
      
    
  
    
      
    
  
    
      
    
  
  
    
  

  
  
  
  
  
  

  

  
  
  
  
  
  
  
    
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.d79152e057e50292de8f0371f157437579e0f14606a88d665ef27376278151108e638fc2c2b5687fa70cc7ec9f616cfe46422a7dface5955ad0b9c4fcd6589be.css"
    integrity="sha512-15FS4FflApLejwNx8VdDdXng8UYGqI1mXvJzdieBURCOY4/CwrVof6cMx&#43;yfYWz&#43;RkIqffrOWVWtC5xPzWWJvg==">

  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js"
    integrity="sha512-b0EXSzoFtoCCD&#43;CMrb&#43;l&#43;3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script>
  
  
  
  
  
  
    
    <script src="/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js" integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7&#43;kfJ6kKCJxQGC&#43;8wm&#43;Bz9JucDjDTGNew=="></script>
  

  
  
  
    
  
  
  
  
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.eb1cab4fe4b9f760444cfbaf02c7410770218e3a2789ec108c0d7d741aa0fbc02e43567bc4e4f2ed05e6acc6096e291a4ff0cf8e6e852fcc31e4be9e48c33c63.js"
      integrity="sha512-6xyrT&#43;S592BETPuvAsdBB3AhjjoniewQjA19dBqg&#43;8AuQ1Z7xOTy7QXmrMYJbikaT/DPjm6FL8wx5L6eSMM8Yw=="
      data-copy="Copy"
      data-copied="Copied"></script>
  

  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>


























  

  

  

  

  








  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
  

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Hands on with Latent Diffusion Models",
    "headline": "Hands on with Latent Diffusion Models",
    
    "inLanguage": "en",
    "url" : "http://localhost:53753/posts/hands-on-latent-diffusion-models/",
    "author" : {
      "@type": "Person",
      "name": "Patrick Schnaß"
    },
    "copyrightYear": "2023",
    "dateCreated": "2023-01-13T09:28:09\u002b00:00",
    "datePublished": "2023-01-13T09:28:09\u002b00:00",
    
    "dateModified": "2023-01-13T09:28:09\u002b00:00",
    
    "keywords": ["DallE","stable-diffusion","latent-diffusion-models","NoCode","HuggingFace","HandsOn"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1729"
  }]
  </script>



  
  

  
  

  
  

  
  

  
  
</head>


















  
  <body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral bf-scrollbar">
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content">
        <span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
        Skip to main content
      </a>
    </div>
    
    
      <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 z-100">
  <div
    id="menu-blur"
    class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl bg-neutral/25 dark:bg-neutral-800/25"></div>
  <div class="relative m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32">
    <div class="main-menu flex items-center w-full gap-2 p-1 pl-0">
  
    
    
      <div>
        <a href="/en/" class="flex">
          <span class="sr-only">Patrick Schnaß | AI Advisory</span>
          
            <img
              src="/favicon/android-chrome-64x64.png"
              width="25"
              height="30"
              class="logo max-h-20 max-w-20 object-scale-down object-left nozoom"
              alt="">
          
        </a>
      </div>
    
  
  
    <a href="/en/" class="text-base font-medium truncate min-w-0 shrink">
      Patrick Schnaß | AI Advisory
    </a>
  
  <div class="flex items-center ms-auto">
    <div class="hidden md:flex">
      <nav class="flex items-center gap-x-5 h-12">
  
    
      
  
    <a
      href="/"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Home"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Home
        </span>
      
    </a>
  

    
      
  
    <a
      href="/#contact"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Contact"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Contact
        </span>
      
    </a>
  

    
      
  
    <a
      href="/#services"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Services"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Services
        </span>
      
    </a>
  

    
      
  
    <a
      href="/about"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="About"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          About
        </span>
      
    </a>
  

    
      
  
    <a
      href="/en/posts"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Blog"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Blog
        </span>
      
    </a>
  

    
      
  
    <a
      href="https://www.linkedin.com/in/patrickschnass/"
      
        target="_blank"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="linkedin"
      title="">
      
        <span >
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span>
        </span>
      
      
    </a>
  

    
      
  
    <a
      href="https://github.com/PatrickPT"
      
        target="_blank"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="github"
      title="">
      
        <span >
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span>
        </span>
      
      
    </a>
  

    
  

  
  

  

  
    <div class="flex items-center">
      <button
        id="appearance-switcher"
        aria-label="Dark mode switcher"
        type="button"
        class="text-base bf-icon-color-hover">
        <div class="flex items-center justify-center dark:hidden">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
        </div>
        <div class="items-center justify-center hidden dark:flex">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
        </div>
      </button>
    </div>
  
</nav>



    </div>
    <div class="flex md:hidden">
      <div class="flex items-center h-14 gap-4">
  

  
    <button
      id="appearance-switcher-mobile"
      type="button"
      aria-label="Dark mode switcher"
      class="flex items-center justify-center text-neutral-900 hover:text-primary-600 dark:text-neutral-200 dark:hover:text-primary-400">
      <div class="dark:hidden">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
      </div>
      <div class="hidden dark:block">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
      </div>
    </button>
  

  
    <input type="checkbox" id="mobile-menu-toggle" autocomplete="off" class="hidden peer">
    <label for="mobile-menu-toggle" class="flex items-center justify-center cursor-pointer bf-icon-color-hover">
      <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>
</span>
    </label>

    <div
      role="dialog"
      aria-modal="true"
      style="scrollbar-gutter: stable;"
      class="fixed inset-0 z-50 invisible overflow-y-auto px-6 py-20 opacity-0 transition-[opacity,visibility] duration-300 peer-checked:visible peer-checked:opacity-100 bg-neutral-50/97 dark:bg-neutral-900/99
      bf-scrollbar">
      <label
        for="mobile-menu-toggle"
        class="fixed end-8 top-5 flex items-center justify-center z-50 h-12 w-12 cursor-pointer select-none rounded-full bf-icon-color-hover border bf-border-color bf-border-color-hover bg-neutral-50 dark:bg-neutral-900">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </label>
      <nav class="mx-auto max-w-md space-y-6">
        
  
    
    <div class="px-2">
      <a
        href="/"
        aria-label="Home"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Home
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/#contact"
        aria-label="Contact"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Contact
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/#services"
        aria-label="Services"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Services
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/about"
        aria-label="About"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          About
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/en/posts"
        aria-label="Blog"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Blog
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="https://www.linkedin.com/in/patrickschnass/"
        aria-label="linkedin"
        
          target="_blank"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
          <span class="flex items-center justify-center h-8 w-8 text-2xl">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span>
          </span>
        
        <span title="" class="text-2xl font-bold tracking-tight">
          
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="https://github.com/PatrickPT"
        aria-label="github"
        
          target="_blank"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
          <span class="flex items-center justify-center h-8 w-8 text-2xl">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span>
          </span>
        
        <span title="" class="text-2xl font-bold tracking-tight">
          
        </span>
        
      </a>

      
    </div>
  

        
  

        
  
    <div
      class="flex flex-wrap items-center [&_span]:text-2xl [&_.translation_button_.icon]:text-4xl! [&_.translation_button_span]:text-base! [&_.translation_.menuhide_span]:text-sm! gap-x-6 ps-2 mt-8 pt-8 border-t bf-border-color">
      

      
    </div>
  

      </nav>
    </div>
  
</div>







    </div>
  </div>
</div>





  </div>
</div>


<script
  type="text/javascript"
  src="/js/background-blur.min.605b3b942818f0ab5a717ae446135ec46b8ee5a2ad12ae56fb90dc2a76ce30c388f9fec8bcc18db15bd47e3fa8a09d779fa12aa9c184cf614a315bc72c6c163d.js"
  integrity="sha512-YFs7lCgY8KtacXrkRhNexGuO5aKtEq5W&#43;5DcKnbOMMOI&#43;f7IvMGNsVvUfj&#43;ooJ13n6EqqcGEz2FKMVvHLGwWPQ=="
  data-blur-id="menu-blur"></script>

    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  
  <article>
    
    

    
    <header id="single_header" class="mt-5 max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Hands on with Latent Diffusion Models
      </h1>
      <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
  
    
  

  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2023-01-13T09:28:09&#43;00:00">13 January 2023</time><span class="px-2 text-primary-500">&middot;</span><span>1729 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">9 mins</span>
    

    
    
  </div>

  

  
  

  
  



      </div>
      
        
  
  
  
  
  
  

  

  
    
    
<div class="flex author">
  
    
    
      
    
    
      
      
      
        
        
        
      
      <img
        class="!mt-0 !mb-0 h-24 w-24 rounded-full me-4"
        width="96"
        height="96"
        alt="Patrick Schnaß"
        src="/patrick_hu_fe0c2285bbac30b1.png"
        data-zoom-src="/patrick_hu_a5a586b022a9f652.png">
    
  
  <div class="place-self-center">
    
      <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
        Author
      </div>
      <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
        Patrick Schnaß
      </div>
    
    
      <div class="text-sm text-neutral-700 dark:text-neutral-400">Helping enterprises turn AI initiatives into profitable business processes</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.linkedin.com/in/patrickschnass/"
          target="_blank"
          aria-label="Linkedin"
          title="Linkedin"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/PatrickPT"
          target="_blank"
          aria-label="Github"
          title="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a
        >
      
    
  </div>

</div>
  </div>
</div>

  

  

  
    <div class="mb-5"></div>
  

      
    </header>

    
    <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
      
      
      
      
      


      <div class="min-w-0 min-h-0 max-w-fit">
        

        <div class="article-content max-w-prose mb-20">
          <p><strong>Prerequitises</strong></p>
<p>To test the models here you need to have an account with <a href="https://huggingface.co/"  target="_blank">HuggingFace</a> - for loading the checkpoint or using the endpoints.
Hugging Face is a community and data science platform that provides:</p>
<ul>
<li>Tools that enable users to build, train and deploy ML models based on open source (OS) code and technologies.</li>
<li>A place where a broad community of data scientists, researchers, and ML engineers can come together and share ideas, get support and contribute to open source projects.</li>
</ul>

<h1 class="relative group">Recap on Latent Diffusion Models
    <div id="recap-on-latent-diffusion-models" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#recap-on-latent-diffusion-models" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>There are mutiple sites and blog posts which explain Latent Diffusion Models including my own <a href="/posts/latent-diffusion-models" >Latent Diffusion Models: What is all the fuzz about?</a></p>
<p>To keep it a bit lightweight i can recommend one which explains everything with diagrams(Because i like diagrams for learning).</p>
<p><a href="https://jalammar.github.io/illustrated-stable-diffusion/"  target="_blank">Blogpost of Jay Alammar</a></p>

<h3 class="relative group">I don&rsquo;t understand anything
    <div id="i-dont-understand-anything" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#i-dont-understand-anything" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>You don&rsquo;t have any idea what this is all about?</p>
<p><strong>You can generate beautiful pictures with the help of AI</strong>
All you need to do is create a prompt and enter it into any tool using an algorithm like stable-diffusion which renders your image then.
So</p>
<ol>
<li>Think of a prompt <a href="https://krea.ai//"  target="_blank">Examples with prompt search</a> and</li>
<li>Go to <a href="https://openai.com/dall-e-2/"  target="_blank">Dall-E</a></li>
<li>Open an account and try it out.</li>
</ol>

<h1 class="relative group">NoCode Quickstart
    <div id="nocode-quickstart" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#nocode-quickstart" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>You are not interested in getting your hands dirty?
You don&rsquo;t want to code?
You just want to produce some nice looking images and test your prompt skills?
You are not willing to pay a certain amount to use the capabilities of OpenAI&rsquo;s <a href="https://openai.com/dall-e-2/"  target="_blank">Dall-E</a>?</p>
<p>Then this is for you:</p>

<h2 class="relative group">Prompt Ideas and References
    <div id="prompt-ideas-and-references" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#prompt-ideas-and-references" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>For starters, do you have any idea what you want to create and how to best create your initial prompt?</p>
<p><em>Yes</em></p>
<p>Awesome, but as in Google Search: When you try to find the correct search prompt you need to tune the semantics of your thoughts to get what you want:
<a href="https://www.howtogeek.com/833169/how-to-write-an-awesome-stable-diffusion-prompt/"  target="_blank">How to write stable-diffusion prompts</a></p>
<p>Of course AI can help you with this:
<a href="https://gustavosta-magicprompt-stable-diffusion.hf.space"  target="_blank">Prompt Tuning</a></p>
<p><em>No</em></p>
<p>No worries, you are not the first one to create a prompt and there are already a lot of examples out there:</p>
<p><a href="https://krea.ai//"  target="_blank">Examples with prompt search</a></p>
<p><a href="https://atlas.nomic.ai/map/809ef16a-5b2d-4291-b772-a913f4c8ee61/9ed7d171-650b-4526-85bf-3592ee51ea31"  target="_blank">Atlas on examples with topics</a></p>

<h2 class="relative group">Use an Endpoint with Stable Diffusion
    <div id="use-an-endpoint-with-stable-diffusion" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#use-an-endpoint-with-stable-diffusion" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>There are already a few websites giving you access to endpoints for free.
I recommend to use one where you still have access to the codebase of the model and some evaluation.
StabilityAI, the creators of stable-diffusion, an open source latent diffusion model host their model on Huggingface and give access to an endpoint (here called spaces) to test it out:</p>
<p><a href="https://stabilityai-stable-diffusion.hf.space/"  target="_blank">Stable Diffusion 2.1 Demo by Stability AI</a></p>
<p><a href="https://huggingface.co/stabilityai/stable-diffusion-2"  target="_blank">Model Card of Stable Diffusion v2</a></p>

<h2 class="relative group">Example
    <div id="example" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#example" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Following prompt:</p>
<p><em>&ldquo;oil painting of a cat sitting on a rainbow&rdquo;</em></p>
<p>becomes after finetuning:</p>
<p><em>&ldquo;oil painting of a cat sitting on a rainbow grass florest, sunset, cliffside ocean scene, diffuse lighting, fantasy, intricate, elegant, highly detailed, lifelike, photorealistic, digital painting, artstation, illustration, concept art, smooth, sharp focus, art by John Collier and Albert Aublet and Krenz Cushart and Artem Demura and Alphonse Mucha&rdquo;</em></p>
<p>and creates this picture with stable-diffusion:
<a href="/posts/2023_01_12_hands_on_latent_diffusion_models/images/cat_rainbow.jpeg" ><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="cat_rainbow"
    src="/posts/2023_01_12_hands_on_latent_diffusion_models/images/cat_rainbow.jpeg"
    ></figure>
</a></p>
<p>I like cats!(Like everyone else on the internet i guess)</p>
<p><strong>Enjoy exploring!</strong></p>
<p>If you are interested in understanding how to create a Notebook with diffusors please see the following section.</p>

<h1 class="relative group">Stable Diffusion
    <div id="stable-diffusion" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#stable-diffusion" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p><em>&hellip;using Hugging Face&rsquo;s <code>diffusers</code></em></p>
<p>*The following section focusses on <strong>inference</strong> and is based on <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb"  target="_blank"><em>Quickstart with diffusers</em></a> and <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb"  target="_blank"><em>Intro on diffusers</em></a></p>
<p><em>If you want to get a more hands-on guide on <strong>training</strong> diffusion models, please have a look at</em>
<a href="https://colab.research.google.com/gist/anton-l/f3a8206dae4125b93f05b1f5f703191d/diffusers_training_example.ipynb"  target="_blank"><em>Training with Diffusers</em></a></p>

<h2 class="relative group">Summary on Diffusion Models
    <div id="summary-on-diffusion-models" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#summary-on-diffusion-models" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Diffusion models are machine learning systems that are trained to <em>denoise</em> random gaussian noise step by step, to get to a sample of interest, such as an <em>image</em>.</p>
<p>The underlying model, often a neural network, is trained to predict a way to slightly denoise the image in each step. After certain number of steps, a sample is obtained.</p>
<p><a href="/posts/2023_01_12_hands_on_latent_diffusion_models/images/diffusion-process.jpg" ><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="stable_diffusion"
    src="/posts/2023_01_12_hands_on_latent_diffusion_models/images/diffusion-process.jpg"
    ></figure>
</a></p>
<p>The diffusion process consists in taking random noise of the size of the desired output and pass it through the model several times. The process ends after a given number of steps, and the output image should represent a sample according to the training data distribution of the model, for instance an image of a cat.</p>
<p>During training we show many samples of a given distribution, such as images of cat. After training, the model will be able to process random noise to generate similar cat images.</p>
<p>Without going in too much detail, the model is usually not trained to directly predict a slightly less noisy image, but rather to predict the &ldquo;noise residual&rdquo; which is the difference between a less noisy image and the input image (for a diffusion model called &ldquo;DDPM&rdquo;).</p>
<p>To do the denoising process, a specific noise scheduling algorithm is thus necessary and &ldquo;wrap&rdquo; the model to define how many diffusion steps are needed for inference as well as how to <em>compute</em> a less noisy image from the model&rsquo;s output.</p>

<h2 class="relative group">Summary on diffusers
    <div id="summary-on-diffusers" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#summary-on-diffusers" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Stable Diffusion is based on a particular type of diffusion model called <strong>Latent Diffusion</strong>, proposed in <a href="https://arxiv.org/abs/2112.10752"  target="_blank">High-Resolution Image Synthesis with Latent Diffusion Models</a>.</p>
<p>It is created by the researchers and engineers from <a href="https://github.com/CompVis"  target="_blank">CompVis</a>, <a href="https://stability.ai/"  target="_blank">Stability AI</a> and <a href="https://laion.ai/"  target="_blank">LAION</a>. It&rsquo;s trained on 512x512 images from a subset of the <a href="https://laion.ai/blog/laion-5b/"  target="_blank">LAION-5B</a> database. This model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and can run on many consumer GPUs.
See the <a href="https://huggingface.co/CompVis/stable-diffusion"  target="_blank">model card</a> for more information.</p>
<p>However, most of the recent research on diffusion models, e.g. DALL-E 2 and Imagen, is unfortunately not accessible to the broader machine learning community and typically remains behind closed doors.</p>
<p>Here comes Hugging Face&rsquo;s library for diffusion model: <a href="https://github.com/huggingface/diffusers"  target="_blank"><code>diffusers</code></a> with the goals to:</p>
<ul>
<li>gather recent diffusion models from independent repositories in a single and long-term maintained project that is built by and for the community,</li>
<li>reproduce high impact machine learning systems such as DALLE and Imagen in a manner that is accessible for the public, and
create an easy to use API that enables one to train their own models or re-use checkpoints from other repositories for inference.</li>
</ul>
<p>The core API of <code>diffusers</code> is divided into three components:</p>
<ol>
<li><strong>Pipelines</strong>: high-level classes designed to rapidly generate samples from popular trained diffusion models in a user-friendly fashion.</li>
<li><strong>Models</strong>: popular architectures for training new diffusion models, <em>e.g.</em> <a href="https://arxiv.org/abs/1505.04597"  target="_blank">UNet</a>.</li>
<li><strong>Schedulers</strong>: various techniques for generating images from noise during <em>inference</em> as well as to generate noisy images for <em>training</em>.</li>
</ol>

<h2 class="relative group">How-to create an Image
    <div id="how-to-create-an-image" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#how-to-create-an-image" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Install diffusers
    <div id="install-diffusers" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#install-diffusers" aria-label="Anchor">#</a>
    </span>
    
</h3>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>!pip install diffusers==0.11.0
</span></span><span style="display:flex;"><span>!pip install transformers scipy ftfy accelerate
</span></span><span style="display:flex;"><span>!pip install &#34;ipywidgets&gt;=7,&lt;8&#34;
</span></span><span style="display:flex;"><span>!pip install safetensors</span></span></code></pre></div></div>

<h3 class="relative group">Input your Hugging Face Token
    <div id="input-your-hugging-face-token" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#input-your-hugging-face-token" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>As mentioned earlier you need a token with huggingface to import the pretrained snapshots</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>from huggingface_hub import notebook_login
</span></span><span style="display:flex;"><span>notebook_login()</span></span></code></pre></div></div>

<h3 class="relative group">Pipeline
    <div id="pipeline" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#pipeline" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p><code>StableDiffusionPipeline</code> is an end-to-end inference pipeline that you can use to generate images from text with just a few lines of code.</p>
<p>First, we load the pre-trained weights of all components of the model. Here we use Stable Diffusion version 2.1 (<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1"  target="_blank">stabilityai/stable-diffusion-2-1</a>), but there are other variants that you may want to try:</p>
<ul>
<li><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5"  target="_blank">runwayml/stable-diffusion-v1-5</a></li>
<li><a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-base"  target="_blank">stabilityai/stable-diffusion-2-1-base</a></li>
<li><a href="https://huggingface.co/stabilityai/stable-diffusion-2-1"  target="_blank">stabilityai/stable-diffusion-2-1</a>. This version can produce images with a resolution of 768x768, while the others work at 512x512.</li>
</ul>
<p>This stable-diffusion-2-1 model is fine-tuned from stable-diffusion-2 (768-v-ema.ckpt) with an additional 55k steps on the same dataset (with punsafe=0.1), and then fine-tuned for another 155k extra steps with punsafe=0.98.</p>
<p>In addition to the model id <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1"  target="_blank">stabilityai/stable-diffusion-2-1</a>, we&rsquo;re also passing a specific <code>torch_dtype</code> to the <code>from_pretrained</code> method.</p>
<p>The weights are loaded from the half-precision branch <a href="https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16"  target="_blank"><code>fp16</code></a> and we need to tell <code>diffusers</code> to expect the weights in float16 precision by passing <code>torch_dtype=torch.float16</code>.</p>
<p>We can import the <code>DDPMPipeline</code>, which will allow you to do inference with a couple of lines of code.
The <code>from_pretrained()</code> method allows downloading the model and its configuration from <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1"  target="_blank">the Hugging Face Hub</a>, a repository of over 60,000 models shared by the community.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>import torch
</span></span><span style="display:flex;"><span>from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_id = &#34;stabilityai/stable-diffusion-2-1&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># Use the DPMSolverMultistepScheduler (DPM-Solver++) scheduler here instead
</span></span><span style="display:flex;"><span>pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
</span></span><span style="display:flex;"><span>pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)</span></span></code></pre></div></div>
<p>The pipe shows now all components contained in your desired process.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>pipe</span></span></code></pre></div></div>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>StableDiffusionPipeline {
</span></span><span style="display:flex;"><span>  &#34;_class_name&#34;: &#34;StableDiffusionPipeline&#34;,
</span></span><span style="display:flex;"><span>  &#34;_diffusers_version&#34;: &#34;0.11.0&#34;,
</span></span><span style="display:flex;"><span>  &#34;feature_extractor&#34;: [
</span></span><span style="display:flex;"><span>    &#34;transformers&#34;,
</span></span><span style="display:flex;"><span>    &#34;CLIPImageProcessor&#34;
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;requires_safety_checker&#34;: false,
</span></span><span style="display:flex;"><span>  &#34;safety_checker&#34;: [
</span></span><span style="display:flex;"><span>    null,
</span></span><span style="display:flex;"><span>    null
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;scheduler&#34;: [
</span></span><span style="display:flex;"><span>    &#34;diffusers&#34;,
</span></span><span style="display:flex;"><span>    &#34;DDIMScheduler&#34;
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;text_encoder&#34;: [
</span></span><span style="display:flex;"><span>    &#34;transformers&#34;,
</span></span><span style="display:flex;"><span>    &#34;CLIPTextModel&#34;
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;tokenizer&#34;: [
</span></span><span style="display:flex;"><span>    &#34;transformers&#34;,
</span></span><span style="display:flex;"><span>    &#34;CLIPTokenizer&#34;
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;unet&#34;: [
</span></span><span style="display:flex;"><span>    &#34;diffusers&#34;,
</span></span><span style="display:flex;"><span>    &#34;UNet2DConditionModel&#34;
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  &#34;vae&#34;: [
</span></span><span style="display:flex;"><span>    &#34;diffusers&#34;,
</span></span><span style="display:flex;"><span>    &#34;AutoencoderKL&#34;
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div></div>

<h3 class="relative group">Model
    <div id="model" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#model" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Instances of the model class are neural networks that take a noisy <code>sample</code> as well as a <code>timestep</code> as inputs to predict a less noisy output <code>sample</code>.</p>
<p>Here a simple <code>UNet2DConditionModel</code> which was released with the <a href="https://arxiv.org/abs/2006.11239"  target="_blank">DDPM Paper</a> is used.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>pipe.unet</span></span></code></pre></div></div>
<p>Similarly to what we&rsquo;ve seen for the pipeline class, we can load the model configuration and weights with one line, using the <code>from_pretrained()</code> method. It caches the model weights locally.</p>

<h3 class="relative group">Scheduler
    <div id="scheduler" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#scheduler" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Schedulers define the noise schedule which is used to add noise to the model during training, and also define the algorithm to <em>compute</em> the slightly less noisy sample given the model output (here <code>noisy_residual</code>).</p>
<p>It is important to stress here that while <em>models</em> have trainable weights, <em>schedulers</em> are usually <em>parameter-free</em> (in the sense they have no trainable weights) and simply define the algorithm to compute the slightly less noisy sample.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>pipe.scheduler</span></span></code></pre></div></div>

<h3 class="relative group">Generate Image
    <div id="generate-image" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#generate-image" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>To generate an image, we simply run the pipeline and don&rsquo;t even need to give it any input, it will generate a random initial noise sample and then iterate the diffusion process. Here we use the inital prompt from above</p>
<p>The pipeline returns as output a dictionary with a generated <code>sample</code> of interest.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>prompt = &#34;oil painting of a cat sitting on a rainbow grass florest, sunset, cliffside ocean scene, diffuse lighting, fantasy, intricate, elegant, highly detailed, lifelike, photorealistic, digital painting, artstation, illustration, concept art, smooth, sharp focus, art by John Collier and Albert Aublet and Krenz Cushart and Artem Demura and Alphonse Mucha&#34;
</span></span><span style="display:flex;"><span>image = pipe(prompt).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>image.save(f&#34;rainbow_cat.png&#34;)</span></span></code></pre></div></div>
<p>Et voila</p>
<p><a href="/posts/2023_01_12_hands_on_latent_diffusion_models/images/cat_sitting_rainbow.png" ><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="cat_rainbow_stable_diffusion"
    src="/posts/2023_01_12_hands_on_latent_diffusion_models/images/cat_sitting_rainbow.png"
    ></figure>
</a></p>
<p>A good video on the topic combining intuition, code and a hands-on can be found on the <a href="https://www.youtube.com/watch?v=ltLNYA3lWAQ"  target="_blank">Youtube Channel by Edan Meyer</a></p>

<h1 class="relative group">References
    <div id="references" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#references" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p><a href="content/posts/2023_01_11_latent_diffusion_models/2023_01_11_latent_diffusion_models" >Latent Diffusion Models: What is all the fuzz about?</a></p>
<p><a href="https://huggingface.co/"  target="_blank">Hugging Face</a></p>
<p><a href="https://jalammar.github.io/illustrated-stable-diffusion/"  target="_blank">Blogpost of Jay Alammar</a></p>
<p><a href="https://openai.com/dall-e-2/"  target="_blank">Dall-E</a></p>
<p><a href="https://krea.ai//"  target="_blank">Examples with prompt search</a></p>
<p><a href="https://atlas.nomic.ai/map/809ef16a-5b2d-4291-b772-a913f4c8ee61/9ed7d171-650b-4526-85bf-3592ee51ea31"  target="_blank">Atlas on examples with topics</a></p>
<p><a href="https://www.howtogeek.com/833169/how-to-write-an-awesome-stable-diffusion-prompt/"  target="_blank">How to write stable-diffusion prompts</a></p>
<p><a href="https://gustavosta-magicprompt-stable-diffusion.hf.space"  target="_blank">Prompt Tuning</a></p>

<h1 class="relative group">Further Links
    <div id="further-links" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#further-links" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p><a href="https://towardsdatascience.com/whats-hugging-face-122f4e7eb11a"  target="_blank">What&rsquo;s HuggingFace on Medium</a></p>

          
          
          
        </div>
        
        

        

        

      </div>

      
      
        
        
          
          
        
        
        
        <script
          type="text/javascript"
          src="/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js"
          integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA=="
          data-oid="views_posts/2023_01_12_hands_on_latent_diffusion_models/2023_01_12_hands_on_latent_diffusion_model.md"
          data-oid-likes="likes_posts/2023_01_12_hands_on_latent_diffusion_models/2023_01_12_hands_on_latent_diffusion_model.md"></script>
      
    </section>

    
    <footer class="pt-8 max-w-prose print:hidden">
      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600">
      <div class="flex justify-between pt-3">
        <span class="flex flex-col">
          
            <a
              class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/summary-chatgpt/">
              <span class="leading-6">
                <span class="inline-block rtl:rotate-180">&larr;</span>&ensp;A short summary on ChatGPT
              </span>
            </a>
            
              <span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2023-01-12T22:34:01&#43;01:00">12 January 2023</time>
              </span>
            
          
        </span>
        <span class="flex flex-col items-end">
          
            <a
              class="flex text-right text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/latent-diffusion-models/">
              <span class="leading-6">
                Latent Diffusion Models: What is all the fuzz about?&ensp;<span class="inline-block rtl:rotate-180">&rarr;</span>
              </span>
            </a>
            
              <span class="me-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2023-01-20T14:50:18&#43;01:00">20 January 2023</time>
              </span>
            
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        


  






<div
  id="scroll-to-top"
  class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200">
  <a
    href="#the-top"
    class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top"
    title="Scroll to top">
    &uarr;
  </a>
</div>

      </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">
    
    
      <p class="text-sm text-neutral-500 dark:text-neutral-400">
          &copy;
          2026
          Patrick Schnaß
      </p>
    

    
    
  </div>
  
    <script>
      mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
        margin: 24,
        background: "rgba(0,0,0,0.5)",
        scrollOffset: 0,
      });
    </script>
  
  
  
  <script
    type="text/javascript"
    src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js"
    integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
    <script>
    function initTabs() {
        const tabClickHandler = (event) => {
            const button = event.target.closest(".tab__button");
            if (!button) return;

            const container = button.closest(".tab__container");
            if (!container) return;

            const tabIndex = parseInt(button.dataset.tabIndex);
            activateTab(container, tabIndex);
        };

        document.addEventListener("click", tabClickHandler);
    }

    function activateTab(container, activeIndex) {
        const buttons = container.querySelectorAll(".tab__button");
        const panels = container.querySelectorAll(".tab__panel");

        buttons.forEach((btn, index) => {
            if (index === activeIndex) {
                btn.classList.add("tab--active");
                btn.setAttribute("aria-selected", "true");
                
                btn.style.borderColor = "var(--color-primary-500)";
                btn.style.color = "var(--color-primary-500)";
            } else {
                btn.classList.remove("tab--active");
                btn.setAttribute("aria-selected", "false");
                btn.style.borderColor = "transparent";
                btn.style.color = "inherit";
            }
        });

        panels.forEach((panel, index) => {
            if (index === activeIndex) {
                panel.classList.remove("hidden");
                panel.classList.add("block");
            } else {
                panel.classList.add("hidden");
                panel.classList.remove("block");
            }
        });
    }

    
    if (document.readyState === "loading") {
        document.addEventListener("DOMContentLoaded", initTabs);
    } else {
        initTabs();
    }
</script>
  
</footer>

    </div>
  </body>
  
</html>
