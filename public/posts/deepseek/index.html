<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=53753&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  
    <meta http-equiv="content-language" content="en">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color">

  
  
    <title>DeepSeek-R1 explored &middot; Patrick Schnaß | AI Advisory</title>
    <meta name="title" content="DeepSeek-R1 explored &middot; Patrick Schnaß | AI Advisory">
  

  
  
    <meta name="description" content="Why DeepSeek-R1 was a significant step for Open Source AI.">
  
  
    <meta name="keywords" content="LLM,GenAI,Architecture,">
  
  
  
  <link rel="canonical" href="http://localhost:53753/posts/deepseek/">
  

  
  
    <meta name="author" content="Patrick Schnaß">
  
  
    
      
        
          <link href="https://www.linkedin.com/in/patrickschnass/" rel="me">
        
      
    
      
        
          <link href="https://github.com/PatrickPT" rel="me">
        
      
    
  

  
  <meta property="og:url" content="http://localhost:53753/posts/deepseek/">
  <meta property="og:site_name" content="Patrick Schnaß | AI Advisory">
  <meta property="og:title" content="DeepSeek-R1 explored">
  <meta property="og:description" content="Why DeepSeek-R1 was a significant step for Open Source AI.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-09T18:30:57+00:00">
    <meta property="article:modified_time" content="2025-02-09T18:30:57+00:00">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="GenAI">
    <meta property="article:tag" content="Architecture">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="DeepSeek-R1 explored">
  <meta name="twitter:description" content="Why DeepSeek-R1 was a significant step for Open Source AI.">

  
  
  
  
    
      
    
  
    
      
    
  
    
      
    
  
  
    
  

  
  
  
  
  
  

  

  
  
  
  
  
  
  
    
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.d79152e057e50292de8f0371f157437579e0f14606a88d665ef27376278151108e638fc2c2b5687fa70cc7ec9f616cfe46422a7dface5955ad0b9c4fcd6589be.css"
    integrity="sha512-15FS4FflApLejwNx8VdDdXng8UYGqI1mXvJzdieBURCOY4/CwrVof6cMx&#43;yfYWz&#43;RkIqffrOWVWtC5xPzWWJvg==">

  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js"
    integrity="sha512-b0EXSzoFtoCCD&#43;CMrb&#43;l&#43;3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script>
  
  
  
  
  
  
    
    <script src="/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js" integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7&#43;kfJ6kKCJxQGC&#43;8wm&#43;Bz9JucDjDTGNew=="></script>
  

  
  
  
    
  
  
  
  
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.eb1cab4fe4b9f760444cfbaf02c7410770218e3a2789ec108c0d7d741aa0fbc02e43567bc4e4f2ed05e6acc6096e291a4ff0cf8e6e852fcc31e4be9e48c33c63.js"
      integrity="sha512-6xyrT&#43;S592BETPuvAsdBB3AhjjoniewQjA19dBqg&#43;8AuQ1Z7xOTy7QXmrMYJbikaT/DPjm6FL8wx5L6eSMM8Yw=="
      data-copy="Copy"
      data-copied="Copied"></script>
  

  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>


























  

  

  

  

  








  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
  

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "DeepSeek-R1 explored",
    "headline": "DeepSeek-R1 explored",
    
    "inLanguage": "en",
    "url" : "http://localhost:53753/posts/deepseek/",
    "author" : {
      "@type": "Person",
      "name": "Patrick Schnaß"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-02-09T18:30:57\u002b00:00",
    "datePublished": "2025-02-09T18:30:57\u002b00:00",
    
    "dateModified": "2025-02-09T18:30:57\u002b00:00",
    
    "keywords": ["LLM","GenAI","Architecture"],
    
    "mainEntityOfPage": "true",
    "wordCount": "2326"
  }]
  </script>



  
  

  
  

  
  

  
  

  
  
</head>


















  
  <body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral bf-scrollbar">
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content">
        <span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
        Skip to main content
      </a>
    </div>
    
    
      <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 z-100">
  <div
    id="menu-blur"
    class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl bg-neutral/25 dark:bg-neutral-800/25"></div>
  <div class="relative m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32">
    <div class="main-menu flex items-center w-full gap-2 p-1 pl-0">
  
    
    
      <div>
        <a href="/en/" class="flex">
          <span class="sr-only">Patrick Schnaß | AI Advisory</span>
          
            <img
              src="/favicon/android-chrome-64x64.png"
              width="25"
              height="30"
              class="logo max-h-20 max-w-20 object-scale-down object-left nozoom"
              alt="">
          
        </a>
      </div>
    
  
  
    <a href="/en/" class="text-base font-medium truncate min-w-0 shrink">
      Patrick Schnaß | AI Advisory
    </a>
  
  <div class="flex items-center ms-auto">
    <div class="hidden md:flex">
      <nav class="flex items-center gap-x-5 h-12">
  
    
      
  
    <a
      href="/"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Home"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Home
        </span>
      
    </a>
  

    
      
  
    <a
      href="/#contact"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Contact"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Contact
        </span>
      
    </a>
  

    
      
  
    <a
      href="/#services"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Services"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Services
        </span>
      
    </a>
  

    
      
  
    <a
      href="/about"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="About"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          About
        </span>
      
    </a>
  

    
      
  
    <a
      href="/en/posts"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="Blog"
      title="">
      
      
        <span class="text-base font-medium break-normal">
          Blog
        </span>
      
    </a>
  

    
      
  
    <a
      href="https://www.linkedin.com/in/patrickschnass/"
      
        target="_blank"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="linkedin"
      title="">
      
        <span >
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span>
        </span>
      
      
    </a>
  

    
      
  
    <a
      href="https://github.com/PatrickPT"
      
        target="_blank"
      
      class="flex items-center bf-icon-color-hover"
      aria-label="github"
      title="">
      
        <span >
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span>
        </span>
      
      
    </a>
  

    
  

  
  

  

  
    <div class="flex items-center">
      <button
        id="appearance-switcher"
        aria-label="Dark mode switcher"
        type="button"
        class="text-base bf-icon-color-hover">
        <div class="flex items-center justify-center dark:hidden">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
        </div>
        <div class="items-center justify-center hidden dark:flex">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
        </div>
      </button>
    </div>
  
</nav>



    </div>
    <div class="flex md:hidden">
      <div class="flex items-center h-14 gap-4">
  

  
    <button
      id="appearance-switcher-mobile"
      type="button"
      aria-label="Dark mode switcher"
      class="flex items-center justify-center text-neutral-900 hover:text-primary-600 dark:text-neutral-200 dark:hover:text-primary-400">
      <div class="dark:hidden">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
      </div>
      <div class="hidden dark:block">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
      </div>
    </button>
  

  
    <input type="checkbox" id="mobile-menu-toggle" autocomplete="off" class="hidden peer">
    <label for="mobile-menu-toggle" class="flex items-center justify-center cursor-pointer bf-icon-color-hover">
      <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>
</span>
    </label>

    <div
      role="dialog"
      aria-modal="true"
      style="scrollbar-gutter: stable;"
      class="fixed inset-0 z-50 invisible overflow-y-auto px-6 py-20 opacity-0 transition-[opacity,visibility] duration-300 peer-checked:visible peer-checked:opacity-100 bg-neutral-50/97 dark:bg-neutral-900/99
      bf-scrollbar">
      <label
        for="mobile-menu-toggle"
        class="fixed end-8 top-5 flex items-center justify-center z-50 h-12 w-12 cursor-pointer select-none rounded-full bf-icon-color-hover border bf-border-color bf-border-color-hover bg-neutral-50 dark:bg-neutral-900">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </label>
      <nav class="mx-auto max-w-md space-y-6">
        
  
    
    <div class="px-2">
      <a
        href="/"
        aria-label="Home"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Home
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/#contact"
        aria-label="Contact"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Contact
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/#services"
        aria-label="Services"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Services
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/about"
        aria-label="About"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          About
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="/en/posts"
        aria-label="Blog"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
        <span title="" class="text-2xl font-bold tracking-tight">
          Blog
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="https://www.linkedin.com/in/patrickschnass/"
        aria-label="linkedin"
        
          target="_blank"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
          <span class="flex items-center justify-center h-8 w-8 text-2xl">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span>
          </span>
        
        <span title="" class="text-2xl font-bold tracking-tight">
          
        </span>
        
      </a>

      
    </div>
  
    
    <div class="px-2">
      <a
        href="https://github.com/PatrickPT"
        aria-label="github"
        
          target="_blank"
        
        class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200">
        
          <span class="flex items-center justify-center h-8 w-8 text-2xl">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span>
          </span>
        
        <span title="" class="text-2xl font-bold tracking-tight">
          
        </span>
        
      </a>

      
    </div>
  

        
  

        
  
    <div
      class="flex flex-wrap items-center [&_span]:text-2xl [&_.translation_button_.icon]:text-4xl! [&_.translation_button_span]:text-base! [&_.translation_.menuhide_span]:text-sm! gap-x-6 ps-2 mt-8 pt-8 border-t bf-border-color">
      

      
    </div>
  

      </nav>
    </div>
  
</div>







    </div>
  </div>
</div>





  </div>
</div>


<script
  type="text/javascript"
  src="/js/background-blur.min.605b3b942818f0ab5a717ae446135ec46b8ee5a2ad12ae56fb90dc2a76ce30c388f9fec8bcc18db15bd47e3fa8a09d779fa12aa9c184cf614a315bc72c6c163d.js"
  integrity="sha512-YFs7lCgY8KtacXrkRhNexGuO5aKtEq5W&#43;5DcKnbOMMOI&#43;f7IvMGNsVvUfj&#43;ooJ13n6EqqcGEz2FKMVvHLGwWPQ=="
  data-blur-id="menu-blur"></script>

    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  
  <article>
    
    

    
    <header id="single_header" class="mt-5 max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        DeepSeek-R1 explored
      </h1>
      <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
  
    
  

  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-02-09T18:30:57&#43;00:00">9 February 2025</time><span class="px-2 text-primary-500">&middot;</span><span>2326 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">11 mins</span>
    

    
    
  </div>

  

  
  

  
  



      </div>
      
        
  
  
  
  
  
  

  

  
    
    
<div class="flex author">
  
    
    
      
    
    
      
      
      
        
        
        
      
      <img
        class="!mt-0 !mb-0 h-24 w-24 rounded-full me-4"
        width="96"
        height="96"
        alt="Patrick Schnaß"
        src="/patrick_hu_fe0c2285bbac30b1.png"
        data-zoom-src="/patrick_hu_a5a586b022a9f652.png">
    
  
  <div class="place-self-center">
    
      <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
        Author
      </div>
      <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
        Patrick Schnaß
      </div>
    
    
      <div class="text-sm text-neutral-700 dark:text-neutral-400">Helping enterprises turn AI initiatives into profitable business processes</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.linkedin.com/in/patrickschnass/"
          target="_blank"
          aria-label="Linkedin"
          title="Linkedin"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/PatrickPT"
          target="_blank"
          aria-label="Github"
          title="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a
        >
      
    
  </div>

</div>
  </div>
</div>

  

  

  
    <div class="mb-5"></div>
  

      
    </header>

    
    <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
      
      
      
      
      


      <div class="min-w-0 min-h-0 max-w-fit">
        

        <div class="article-content max-w-prose mb-20">
          
<h1 class="relative group">TL;DR
    <div id="tldr" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#tldr" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>This blog post explains how the recent release of DeepSeek may benefit the open source community and why it is considered a game changer for AI industry.</p>
<hr>

<h1 class="relative group">Why all the rumors?
    <div id="why-all-the-rumors" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#why-all-the-rumors" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>DeepSeek-R1 represents a significant innovation in the AI landscape, outperforming or rivaling top commercial models including reasoning capabilities. Previously, such sophisticated models were exclusive to tech giants like OpenAI and Google, but R1 now joins this category as the only open-weights model of its kind. Its Open Source approach including a MIT license further amplifies its disruptive potential, enabling unrestricted commercial use, even for direct competitors, without costly R&amp;D.</p>
<p>Beyond accessibility, DeepSeek-R1 heats innovation by openly sharing its cost-effective training methodology, challenging the narrative that advanced AI requires exorbitant GPU investments. Operationally, it’s remarkably affordable: output tokens cost 30x less than OpenAI’s, and input tokens are 55x cheaper.</p>
<p>R1’s blend of performance, openness, innovation and affordability could signal that open-source can still play a pivotal role in the AI race.</p>
<p><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="Intro"
    src="/posts/2025_02_01_Open_Source_Innovation/images/Intro_picture.jpg"
    ></figure>
</p>
<p>And yes, it&rsquo;s a widely discussed topic in the AI community. and still i found it very interesting and entertaining.</p>
<hr>

<h1 class="relative group">DeepSeek Technical Paper in a Nutshell
    <div id="deepseek-technical-paper-in-a-nutshell" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#deepseek-technical-paper-in-a-nutshell" aria-label="Anchor">#</a>
    </span>
    
</h1>

<h2 class="relative group">Key Training Process &amp; Innovations in DeepSeek-R1
    <div id="key-training-process--innovations-in-deepseek-r1" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#key-training-process--innovations-in-deepseek-r1" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">1. Two Core Models
    <div id="1-two-core-models" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#1-two-core-models" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li>
<p><strong>DeepSeek-R1-Zero</strong>:</p>
<ul>
<li><strong>Pure RL Training</strong>: Trained <em>directly</em> on the base model (DeepSeek-V3-Base) <strong>without supervised fine-tuning (SFT)</strong>.</li>
<li><strong>Algorithm</strong>: Uses <strong>GRPO</strong> (Group Relative Policy Optimization), a critic-free RL method that estimates baselines from group scores.</li>
<li><strong>Reward Design</strong>: Relies on <strong>rule-based rewards</strong> (accuracy + formatting) instead of neural reward models to avoid reward hacking.</li>
<li><strong>Emergent Behaviors</strong>: Self-verification, reflection, and extended reasoning (e.g., &ldquo;aha moments&rdquo;) emerged naturally during RL.</li>
<li><strong>Limitations</strong>: Poor readability, language mixing, and formatting inconsistencies.</li>
</ul>
</li>
<li>
<p><strong>DeepSeek-R1</strong>:</p>
<ul>
<li><strong>Cold-Start Data</strong>: Starts with <strong>thousands of curated CoT examples</strong> to fine-tune the base model, improving readability and stability.</li>
<li><strong>Multi-Stage Training</strong>:
<ol>
<li><strong>Cold-Start SFT</strong>: Initial fine-tuning for readable CoT generation.</li>
<li><strong>Reasoning-Oriented RL</strong>: Applies GRPO with added <strong>language consistency rewards</strong>.</li>
<li><strong>Rejection Sampling + SFT</strong>: Generates high-quality data (600k reasoning + 200k non-reasoning samples) for retraining.</li>
<li><strong>Final RL Alignment</strong>: Balances reasoning performance with human preferences (helpfulness/harmlessness).</li>
</ol>
</li>
</ul>
</li>
</ul>

<h3 class="relative group">2. Key Innovations
    <div id="2-key-innovations" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#2-key-innovations" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ol>
<li>
<p><strong>RL-First Approach</strong>:</p>
<ul>
<li>Proves reasoning capabilities can be <strong>incentivized purely through RL</strong> without SFT (novel for open research).</li>
<li>Achieves OpenAI-o1-0912-level performance (e.g., 71% → 86.7% on AIME with majority voting).</li>
</ul>
</li>
<li>
<p><strong>Cold-Start Strategy</strong>:</p>
<ul>
<li>Addresses R1-Zero’s limitations by seeding RL with human-prioritized data (readability, structured outputs).</li>
</ul>
</li>
<li>
<p><strong>Distillation Efficiency</strong>:</p>
<ul>
<li>Smaller models (1.5B–70B) distilled from DeepSeek-R1 outperform RL-trained counterparts (e.g., 72.6% vs. 47% on AIME for Qwen-32B).</li>
<li>Distilled models surpass GPT-4o/Claude-3.5-Sonnet in math/coding tasks despite smaller size.</li>
</ul>
</li>
<li>
<p><strong>Rule-Based Rewards</strong>:</p>
<ul>
<li>Avoids neural reward models, simplifying training and reducing hacking risks.</li>
</ul>
</li>
</ol>

<h3 class="relative group">3. Critical Challenges &amp; Insights
    <div id="3-critical-challenges--insights" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#3-critical-challenges--insights" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li><strong>Failed Attempts</strong>:
<ul>
<li><strong>Process Reward Models (PRMs)</strong>: Struggled with fine-grained step validation and scalability.</li>
<li><strong>Monte Carlo Tree Search (MCTS)</strong>: Token-generation complexity made iterative improvement impractical.</li>
</ul>
</li>
<li><strong>Key Insight</strong>: Distillation is more cost-effective than RL for smaller models, but advancing SOTA requires large-scale RL on powerful base models.</li>
</ul>
<hr>

<h1 class="relative group">Foundational concepts used in DeepSeek-R1
    <div id="foundational-concepts-used-in-deepseek-r1" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#foundational-concepts-used-in-deepseek-r1" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>To gain a clearer insight into the core framework of DeepSeek-R1, let’s break down its foundational concepts:</p>
<p><strong>Reinforcement Learning (RL):</strong> This approach involves a model learning through a system of rewards and penalties tied to its actions, refining its performance over time via trial and error. In the realm of large language models (LLMs), RL can be implemented through techniques such as policy optimization (e.g., Proximal Policy Optimization or PPO), value-based methods (e.g., Q-learning), or combined approaches like actor-critic architectures. For instance, when presented with a prompt like “2 + 2 =”, the model might receive a reward of +1 for generating the correct answer “4” and a penalty of -1 for any incorrect response. In advanced LLMs, rewards are often derived from human feedback (RLHF) or automated evaluation systems like GRPO.</p>
<p><strong>Supervised Fine-Tuning (SFT):</strong> This process involves retraining a base model using a labeled dataset to enhance its performance on a specific task. For example, an LLM could be fine-tuned with a dataset of customer service queries and responses to improve its accuracy in addressing common support questions. This method is particularly effective when a substantial amount of labeled data is available.</p>
<p><strong>Cold Start Data:</strong> This refers to a small, minimally labeled dataset used to provide the model with a basic grasp of the task at hand. For instance, a chatbot might be fine-tuned using a simple dataset of frequently asked questions (FAQs) extracted from a website, helping it establish a foundational understanding. This approach is especially useful when labeled data is scarce.</p>
<p><strong>Multi-Stage Training:</strong> In this method, the model undergoes training in distinct phases, each targeting a specific improvement, such as accuracy or alignment with user expectations. For example, a model might first be trained on general text data and then further refined using reinforcement learning based on user feedback to enhance its conversational capabilities.</p>
<p><strong>Rejection Sampling:</strong> This technique involves generating multiple potential outputs from a model, but only retaining those that meet predefined criteria, such as quality or relevance. For example, after a reinforcement learning process, the model might produce several responses, but only the most useful ones are selected for retraining or further use. This ensures that only high-quality outputs contribute to the model’s ongoing improvement.</p>
<hr>

<h1 class="relative group">How Does DeepSeek Work?
    <div id="how-does-deepseek-work" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#how-does-deepseek-work" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>DeepSeek R1 changes the way we think about training AI to reason. Instead of needing huge sets of labeled examples to learn step-by-step logic, R1 shows that a model can develop detailed reasoning skills using only reinforcement learning (RL). Their R1-Zero experiment is the proof-of-concept here—by using a smart reward system, the model learned to work through problems, check its own answers, and even spend extra time on tougher questions. What’s striking is that these skills weren’t explicitly programmed in; they emerged naturally during training.</p>
<p><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="DeepSeek-R1 Architecture"
    src="/posts/2025_02_01_Open_Source_Innovation/images/DeepSeek-R1.drawio.png"
    ></figure>

<em>picture from <a href="https://thelmbook.com/articles/#!./DeepSeek-R1.md"  target="_blank">DeepSeek R1 explained</a></em></p>

<h2 class="relative group">Rethinking Traditional Language Model Training
    <div id="rethinking-traditional-language-model-training" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#rethinking-traditional-language-model-training" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Most language models go through three main phases:</p>
<ol>
<li>
<p><strong>Pre-training:</strong><br>
The model starts by processing huge amounts of text (web pages, books, papers, code, etc.) to learn language basics like grammar, facts, and simple logic. The goal is to predict the next word in a sequence, and by doing this on trillions of tokens, the model builds a rich understanding of language. However, at this stage, it’s not yet good at applying its knowledge to specific tasks.</p>
</li>
<li>
<p><strong>Supervised Finetuning (SFT):</strong><br>
After pre-training, the model gets fine-tuned on curated datasets with instruction-response pairs. This step teaches the model how to follow instructions, answer questions, summarize text, generate code, and even write creatively. High-quality SFT data is crucial—it’s expensive and tough to create but sets the model up to act more like a human assistant.</p>
</li>
<li>
<p><strong>Preference Optimization:</strong><br>
Sometimes called RLHF (Reinforcement Learning from Human Feedback) or direct preference optimization (DPO), this phase aligns the model’s outputs with what people prefer. Human annotators rate different responses, and the model’s behavior is fine-tuned to favor outputs that score higher. This helps with more subtle aspects like tone, consistency, and safety.</p>
</li>
</ol>
<hr>

<h2 class="relative group">The Role of Chain of Thought
    <div id="the-role-of-chain-of-thought" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#the-role-of-chain-of-thought" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>An interesting trick is to have the model generate a “chain of thought” (CoT) before giving its final answer. For example, if you ask, “How much is 1+1?”, the model might internally think through different possibilities before settling on 2. This intermediate step improves accuracy, though most of it remains hidden from users. While some models like OpenAI’s o1 have shown great results with CoT, their process remains secret—leading many to speculate about a “secret sauce” of hand-crafted examples.</p>
<hr>

<h2 class="relative group">DeepSeek R1-Zero and R1: Rethinking the Norm
    <div id="deepseek-r1-zero-and-r1-rethinking-the-norm" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#deepseek-r1-zero-and-r1-rethinking-the-norm" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>DeepSeek challenged the usual belief that extensive supervised fine-tuning is necessary. Instead, they showed that a pure reinforcement learning approach, using automatically generated training examples, can yield impressive reasoning skills.</p>
<p><strong>R1-Zero</strong> demonstrates that advanced reasoning (or chain of thought) can emerge without the traditional SFT stage. Built on the DeepSeek-V3-Base architecture (with 671 billion parameters), R1-Zero uses 61 Transformer decoder blocks. The first three blocks use dense attention to capture basic patterns, while the remaining blocks use a mixture of experts (MoE). In the MoE setup, instead of processing every token through every expert, a few specialized networks are activated per token. For example, out of 256 experts in each block, only 8 are used for any given token, making the process both faster and cheaper.</p>
<hr>

<h2 class="relative group">Group Relative Policy Optimization (GRPO)
    <div id="group-relative-policy-optimization-grpo" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#group-relative-policy-optimization-grpo" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>One of DeepSeek’s key innovations is GRPO—a twist on the common RLHF technique known as Proximal Policy Optimization (PPO). In traditional RLHF, you need several components:</p>
<ul>
<li><strong>Policy Model (Actor):</strong> The model that generates text.</li>
<li><strong>Reference Model:</strong> Usually the frozen SFT model.</li>
<li><strong>Reward Model:</strong> Trained with human ratings.</li>
<li><strong>Value Model (Critic):</strong> Predicts expected rewards for each token.</li>
</ul>
<p><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="PPO vs GRPO"
    src="/posts/2025_02_01_Open_Source_Innovation/images/PPO-GRPO.png"
    ></figure>

<em>picture from <a href="https://thelmbook.com/articles/#!./DeepSeek-R1.md"  target="_blank">DeepSeek R1 explained</a></em></p>
<p>PPO relies on these to update the model based on how much better or worse each token is compared to what was expected. But GRPO cuts out the value model. Instead, it samples multiple outputs for each prompt and uses the group’s average reward as a baseline. For example, if you generate 64 responses for a math problem and one gets 0.9 while the average is 0.7, that answer gets a boost (an advantage of 0.2). This group-based method not only simplifies things but also encourages some pretty neat behavior: the model starts to self-correct, having “Aha moments” where it notices and fixes its own mistakes without explicit instructions.</p>
<hr>

<h2 class="relative group">Reward Structure: Accuracy and Format
    <div id="reward-structure-accuracy-and-format" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#reward-structure-accuracy-and-format" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>DeepSeek’s reward system is another breakthrough. Rather than using a convoluted multi-network approach (which can be tricked by “reward hacking”), they use a simple, rule-based system. The model earns rewards in two main ways:</p>
<ul>
<li>
<p><strong>Accuracy Rewards:</strong><br>
The model’s answer is checked automatically. For math problems, it must match the exact expected answer (often formatted in a specific way). For coding, the generated code is executed and its output is compared to a known correct result.</p>
</li>
<li>
<p><strong>Format Rewards:</strong><br>
The model is also rewarded for writing its reasoning clearly between designated tags (like <code>&lt;think&gt;</code> and <code>&lt;/think&gt;</code>). This ensures that its chain of thought is not only correct but also readable and well-structured.</p>
</li>
</ul>
<p>What’s impressive is that this whole system doesn’t rely on human feedback. It scales up quickly because the model can evaluate millions of responses automatically, reducing bias and opening the door to discovering new problem-solving approaches.</p>
<p><figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="Intro"
    src="/posts/2025_02_01_Open_Source_Innovation/images/GRPO.jpeg"
    ></figure>
</p>
<hr>

<h2 class="relative group">Multi-Stage Training Process in DeepSeek R1
    <div id="multi-stage-training-process-in-deepseek-r1" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#multi-stage-training-process-in-deepseek-r1" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Building on the insights from R1-Zero, DeepSeek’s full R1 model uses a four-stage training pipeline to overcome some issues seen in R1-Zero, like messy formatting or mixing languages:</p>
<ol>
<li>
<p><strong>Cold Start Stage:</strong><br>
Here, a small dataset of detailed chain-of-thought examples is gathered. These examples come from several sources: few-shot prompting, cleaned-up outputs from R1-Zero, and even some human post-processing. This dataset helps stabilize the early phase of RL training.</p>
</li>
<li>
<p><strong>Intensive Reinforcement Learning Stage:</strong><br>
The model then undergoes rigorous RL focused on reasoning tasks such as math, coding, and logic puzzles. This stage uses the GRPO framework and adds extra rewards to enforce language consistency—minimizing the tendency to mix languages mid-response.</p>
</li>
<li>
<p><strong>General Finetuning Stage:</strong><br>
At this point, the model isn’t just about reasoning anymore. It’s further tuned with additional data covering general text tasks like writing, translation, and role-playing. Researchers curate about 600,000 reasoning-related examples and another 200,000 non-reasoning samples, combining them for broader capabilities.</p>
</li>
<li>
<p><strong>Preference Optimization Stage:</strong><br>
Finally, a general-purpose RL process is applied to fine-tune the outputs so that they align better with human preferences, refining tone, style, and overall quality.</p>
</li>
</ol>
<hr>

<h1 class="relative group">Implications
    <div id="implications" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#implications" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>The release of DeepSeek-R1 was not just another model but it represents a shift in how advanced LLMs can be built and deployed:</p>

<h2 class="relative group">Democratization of Advanced AI:
    <div id="democratization-of-advanced-ai" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#democratization-of-advanced-ai" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>Against the overwhelming trend of closed-source models, DeepSeek-R1 is open-sourced and still reaches on-par performance with commercial models. This openness invites collaborative improvements and accelerates innovation in AI.</p>

<h2 class="relative group">Cost-Effective Scaling:
    <div id="cost-effective-scaling" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#cost-effective-scaling" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>DeepSeek-R1 dramatically reduces token costs (30× cheaper for outputs and 55× cheaper for inputs than comparable commercial models). This cost efficiency challenges the narrative that state-of-the-art reasoning demands vast GPU clusters and massive labeled datasets, initiating new innovation in AI training paradigms.</p>

<h2 class="relative group">Validation of Pure RL for Reasoning:
    <div id="validation-of-pure-rl-for-reasoning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#validation-of-pure-rl-for-reasoning" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>The success of DeepSeek-R1-Zero proves that advanced reasoning can emerge solely through reinforcement learning. This breakthrough inspires further research into RL-first training paradigms, potentially reshaping how future LLMs are developed.</p>

<h2 class="relative group">Influence on Commercial Strategies:
    <div id="influence-on-commercial-strategies" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#influence-on-commercial-strategies" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>By openly publishing its training methods—including its efficient distillation and group-based optimization techniques—DeepSeek-R1 pressures commercial entities to adopt more transparent and community-friendly approaches. This could lead to a more competitive and innovative AI ecosystem.</p>
<hr>

<h1 class="relative group">Pitfalls
    <div id="pitfalls" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#pitfalls" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>While DeepSeek-R1 sets a new standard, several challenges remain:</p>
<ul>
<li>
<p><strong>Readability and Formatting:</strong><br>
The initial R1-Zero model exhibited issues such as poor readability and language mixing. Although the multi-stage training process addresses these concerns, some residual inconsistencies may persist in complex scenarios.</p>
</li>
<li>
<p><strong>Inference Latency:</strong><br>
DeepSeek-R1’s chain-of-thought generation is computationally intensive. Inference times are slower compared to models optimized solely for speed, which may limit its use in latency-critical applications.</p>
</li>
<li>
<p><strong>Limited Inference Flexibility:</strong><br>
The current API version does not support many adjustable parameters (e.g., temperature, top_p, etc.), making it harder to fine-tune output behavior for production environments.</p>
</li>
<li>
<p><strong>Risk of Overfitting to Rule-Based Rewards:</strong><br>
Relying on fixed, rule-based rewards simplifies training but may also constrain the model’s adaptability. In cases where nuanced human judgment is required, this approach might not capture every subtlety.</p>
</li>
<li>
<p><strong>Scalability of Pure RL:</strong><br>
Although pure RL has proven effective here, it typically requires longer training times and can be sensitive to reward design. The balance between cost-effectiveness and training complexity remains a delicate one.</p>
</li>
</ul>
<hr>

<h1 class="relative group">Conclusion
    <div id="conclusion" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#conclusion" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>DeepSeek R1 is a major step forward in AI because it shows that you don’t need a massive, manually curated dataset to get a model to reason well. Instead, by leveraging pure reinforcement learning and a clever reward system, the model learns to think through problems, self-correct, and provide clear, structured explanations on its own.</p>
<p>R1-Zero, combined with the refined multi-stage training process in R1, not only offers competitive performance on tough benchmarks but does so more efficiently and cost-effectively. As these techniques evolve, they’re likely to shape the next generation of Open Source AI models.</p>
<hr>

<h1 class="relative group">Ressources
    <div id="ressources" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#ressources" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p><a href="https://thelmbook.com/articles/#!./DeepSeek-R1.md"  target="_blank">https://thelmbook.com/articles/#!./DeepSeek-R1.md</a></p>
<p><a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf"  target="_blank">https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf</a></p>
<p><a href="https://www.vellum.ai/blog/the-training-of-deepseek-r1-and-ways-to-use-it"  target="_blank">https://www.vellum.ai/blog/the-training-of-deepseek-r1-and-ways-to-use-it</a></p>
<p><a href="https://arxiv.org/pdf/2405.20304"  target="_blank">https://arxiv.org/pdf/2405.20304</a></p>

          
          
          
        </div>
        
        

        

        

      </div>

      
      
        
        
          
          
        
        
        
        <script
          type="text/javascript"
          src="/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js"
          integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA=="
          data-oid="views_posts/2025_02_01_Open_Source_Innovation/2025_02_01_Open_Source_Innovation.md"
          data-oid-likes="likes_posts/2025_02_01_Open_Source_Innovation/2025_02_01_Open_Source_Innovation.md"></script>
      
    </section>

    
    <footer class="pt-8 max-w-prose print:hidden">
      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600">
      <div class="flex justify-between pt-3">
        <span class="flex flex-col">
          
            <a
              class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/blt/">
              <span class="leading-6">
                <span class="inline-block rtl:rotate-180">&larr;</span>&ensp;A view on BLT
              </span>
            </a>
            
              <span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2025-01-02T09:30:57&#43;00:00">2 January 2025</time>
              </span>
            
          
        </span>
        <span class="flex flex-col items-end">
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        


  






<div
  id="scroll-to-top"
  class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200">
  <a
    href="#the-top"
    class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top"
    title="Scroll to top">
    &uarr;
  </a>
</div>

      </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">
    
    
      <p class="text-sm text-neutral-500 dark:text-neutral-400">
          &copy;
          2026
          Patrick Schnaß
      </p>
    

    
    
  </div>
  
    <script>
      mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
        margin: 24,
        background: "rgba(0,0,0,0.5)",
        scrollOffset: 0,
      });
    </script>
  
  
  
  <script
    type="text/javascript"
    src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js"
    integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
    <script>
    function initTabs() {
        const tabClickHandler = (event) => {
            const button = event.target.closest(".tab__button");
            if (!button) return;

            const container = button.closest(".tab__container");
            if (!container) return;

            const tabIndex = parseInt(button.dataset.tabIndex);
            activateTab(container, tabIndex);
        };

        document.addEventListener("click", tabClickHandler);
    }

    function activateTab(container, activeIndex) {
        const buttons = container.querySelectorAll(".tab__button");
        const panels = container.querySelectorAll(".tab__panel");

        buttons.forEach((btn, index) => {
            if (index === activeIndex) {
                btn.classList.add("tab--active");
                btn.setAttribute("aria-selected", "true");
                
                btn.style.borderColor = "var(--color-primary-500)";
                btn.style.color = "var(--color-primary-500)";
            } else {
                btn.classList.remove("tab--active");
                btn.setAttribute("aria-selected", "false");
                btn.style.borderColor = "transparent";
                btn.style.color = "inherit";
            }
        });

        panels.forEach((panel, index) => {
            if (index === activeIndex) {
                panel.classList.remove("hidden");
                panel.classList.add("block");
            } else {
                panel.classList.add("hidden");
                panel.classList.remove("block");
            }
        });
    }

    
    if (document.readyState === "loading") {
        document.addEventListener("DOMContentLoaded", initTabs);
    } else {
        initTabs();
    }
</script>
  
</footer>

    </div>
  </body>
  
</html>
